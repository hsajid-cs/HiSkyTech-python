{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('spam_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are not needed\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('\\r\\n',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a stemmer object\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the data\n",
    "corpus = [] # list to store the preprocessed data\n",
    "stopwords_set = set(stopwords.words('english')) # set of stopwords\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text = df['text'].iloc[i].lower() # converting the text to lowercase\n",
    "    text = text.translate(str.maketrans('','',string.punctuation)).split() # removing punctuations and splitting the text into words\n",
    "    text = [stemmer.stem(word) for word in text if word not in stopwords_set] # stemming the words and removing the stopwords\n",
    "    text = ' '.join(text) # joining the words back to form the text\n",
    "    corpus.append(text) # appending the text to the corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer() # creating a CountVectorizer object\n",
    "\n",
    "X = vectorizer.fit_transform(corpus).toarray() # creating the feature matrix X\n",
    "Y = df['label_num'] # creating the target variable Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2) # splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847678916827853"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB() # creating a Multinomial Naive Bayes model\n",
    "\n",
    "model.fit(x_train, y_train) # fitting the model on the training data\n",
    "model.score(x_train, y_train) # calculating the accuracy of the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess data and transform it into a format that can be fed to the model\n",
    "\n",
    "def transform(email):\n",
    "    stopwords_set = stopwords.words('english')\n",
    "    email = email.replace('\\r\\n',' ')\n",
    "    email = email.lower()\n",
    "    email = email.translate(str.maketrans(\"\",\"\",string.punctuation)).split()\n",
    "    email = [stemmer.stem(word) for word in email if word not in stopwords_set]\n",
    "    email = ' '.join(email)\n",
    "    data = vectorizer.transform([email]).toarray()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model on a sample email\n",
    "\n",
    "email = \"\"\"\n",
    "Subject: Congratulations! You've won a prize!\n",
    "\n",
    "Dear User,\n",
    "\n",
    "Congratulations! You have been selected as the winner of our $1,000,000 prize! To claim your prize, please click the link below and provide your personal information.\n",
    "\n",
    "[Claim your prize now!](http://example.com)\n",
    "\n",
    "Hurry, this offer is only valid for the next 24 hours.\n",
    "\n",
    "Best regards,\n",
    "The Prize Team\n",
    "\"\"\"\n",
    "\n",
    "X = transform(email)\n",
    "\n",
    "model.predict(X)\n",
    "\n",
    "# output will be 1 as the email is spam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model on a sample email\n",
    "\n",
    "email = \"\"\"\n",
    "Subject: Meeting Reminder\n",
    "\n",
    "Dear Team,\n",
    "\n",
    "This is a reminder for our weekly meeting scheduled for tomorrow at 10 AM in the conference room. Please make sure to bring the latest project updates and any questions you may have.\n",
    "\n",
    "Agenda:\n",
    "1. Project progress review\n",
    "2. Upcoming deadlines\n",
    "3. Any issues or roadblocks\n",
    "4. Q&A\n",
    "\n",
    "Looking forward to seeing you all there.\n",
    "\n",
    "Best regards,\n",
    "John Doe\n",
    "Project Manager\n",
    "\"\"\"\n",
    "\n",
    "X = transform(email)\n",
    "\n",
    "model.predict(X)\n",
    "\n",
    "# output will be 0 as the email is not spam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
